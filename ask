#!/bin/bash
set -e

# Initial Env & arugments
dev_mode=0
source .env
source .venv/bin/activate

# Check local llm execution
curl -s --head http://localhost:8000 > /dev/null || { echo "Error: run './start_server' first." ; exit 1;}

# Install libs
if python3 -c "import llama-index, streamlit" &> /dev/null; then
    echo "llama-index is not installed"
    pip install -r requirements.txt
fi

# Read arugments
while [[ "$#" -gt 0 ]]; do
    case "$1" in
        --dev) dev_mode=1; shift;;
        *) shift;;
    esac
done

# Execute scripts
if [ $dev_mode -eq 1 ]; then
    python3 src/backend.py
else
    streamlit run src/frontend.py
fi